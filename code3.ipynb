{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fftpack import dct\n",
    "\n",
    "def compress_with_dct(data, quantization_bits=8):\n",
    "    # Apply 1D DCT along the columns (temporal dimension)\n",
    "    dct_transformed = np.apply_along_axis(dct, axis=0, arr=data)\n",
    "\n",
    "    # Quantization\n",
    "    quantized_coeffs = np.round(dct_transformed * (2 ** quantization_bits))\n",
    "\n",
    "    # Encoding (pickle is used for simplicity; you may choose a different encoding method)\n",
    "    encoded_data = pickle.dumps(quantized_coeffs)\n",
    "\n",
    "    return encoded_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fftpack import idct\n",
    "\n",
    "def decompress_with_dct(encoded_data, quantization_bits=8, original_shape=None):\n",
    "    # Decoding\n",
    "    quantized_coeffs = pickle.loads(encoded_data)\n",
    "\n",
    "    # Dequantization\n",
    "    dct_transformed = quantized_coeffs / (2 ** quantization_bits)\n",
    "\n",
    "    # Apply inverse DCT along the columns (temporal dimension)\n",
    "    reconstructed_data = np.apply_along_axis(idct, axis=0, arr=dct_transformed)\n",
    "\n",
    "    # Reshape to the original shape if provided\n",
    "    if original_shape is not None:\n",
    "        reconstructed_data = reconstructed_data.reshape(original_shape)\n",
    "\n",
    "    return reconstructed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Original Data: 156389232 bytes\n",
      "Size of Compressed Data: 213688181 bytes\n",
      "Compression Ratio: 0.73\n",
      "Number of Rows in Original Data: 108004\n",
      "Number of Columns in Original Data: 70\n",
      "Number of Bytes in Original Data per Row: 1447.99 bytes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Assuming 'output.csv' is your CSV file with four columns of data\n",
    "    csv_file_path = 'output2.csv'\n",
    "\n",
    "    data = pd.read_csv('output2.csv')\n",
    "\n",
    "    # Set your preferred parameters for DCT\n",
    "    quantization_bits = 5  # Adjust the number of quantization bits as needed\n",
    "\n",
    "    # Compression using DCT\n",
    "    encoded_result = compress_with_dct(data, quantization_bits=quantization_bits)\n",
    "\n",
    "    # Store the original shape for later reconstruction\n",
    "    original_shape = data.shape\n",
    "\n",
    "    # Decompression using DCT\n",
    "    decompressed_result = decompress_with_dct(encoded_result, quantization_bits=quantization_bits, original_shape=original_shape)\n",
    "\n",
    "    # Convert the decompressed result to a Pandas DataFrame\n",
    "    decompressed_dataframe = pd.DataFrame(decompressed_result, columns=data.columns)\n",
    "\n",
    "    # Save the compressed and decompressed data to new CSV files\n",
    "    pd.DataFrame({'CompressedData': [encoded_result]}).to_csv('compressed_data_dct.csv', index=False)\n",
    "    decompressed_dataframe.to_csv('decompressed_data_dct.csv', index=False)\n",
    "\n",
    "    # Calculate the size of the original and compressed data\n",
    "    original_size = os.path.getsize(csv_file_path)\n",
    "    compressed_size = os.path.getsize('compressed_data_dct.csv')\n",
    "\n",
    "    # Calculate the compression ratio\n",
    "    compression_ratio = original_size / compressed_size\n",
    "\n",
    "    print(f\"Size of Original Data: {original_size} bytes\")\n",
    "    print(f\"Size of Compressed Data: {compressed_size} bytes\")\n",
    "    print(f\"Compression Ratio: {compression_ratio:.2f}\")\n",
    "\n",
    "    # Additional prints for diagnostic purposes\n",
    "    print(f\"Number of Rows in Original Data: {original_shape[0]}\")\n",
    "    print(f\"Number of Columns in Original Data: {original_shape[1]}\")\n",
    "    print(f\"Number of Bytes in Original Data per Row: {original_size / original_shape[0]:.2f} bytes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
